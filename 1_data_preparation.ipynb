{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of wind turbine data\n",
    "\n",
    "Cells in this notebook can be run independently provided the first two (\"Imports\" and \"Preprocessing function...\") are run first.\n",
    "\n",
    "1. [Imports.](#Cell1)\n",
    "1. [Preprocessing function, good for training data as well as testing data.](#Cell2)\n",
    "1. [Preprocess the training data set, output a pickle file.](#Cell3)\n",
    "1. [Preprocess the training data set in Feather format for notebooks running R kernel.](#Cell4)\n",
    "1. [Preprocess the testing data set, output a pickle file.](#Cell5)\n",
    "1. [Preprocess the testing data set in Feather format for notebooks running R kernel.](#Cell6)\n",
    "1. [Preprocess the solution file (the testing data set with TARGETVAR included). Output in pickle and Feather.](#Cell7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Imports.\n",
    "'''\n",
    "import feather\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocessing function, good for training data as well as testing data.\n",
    "'''\n",
    "def preProcess(fname, Nroll=3, keepID=False):\n",
    "    '''\n",
    "    Read in the wind turbine data, store in a Pandas dataframe, and rearrange.\n",
    "\n",
    "    1.  Records in the input csv file are assumed to have the following form:\n",
    "            ID, ZONEID, TIMESTAMP, TARGETVAR, U10, V10, U100, V100\n",
    "        where:\n",
    "            ID =         Unique ID for each observation\n",
    "            ZONEID =     Zone/Turbine ID, a number between 1 and 10\n",
    "            TIMESTAMP =  Time of observation, in the format \"YYYYMMDD h:mm\" or \"YYYYMMDD hh:mm\"\n",
    "            TARGETVAR =  Wind turbine output (only present in the training data set)\n",
    "            U10 =        Zonal Wind Vector at 10 m\n",
    "            V10 =        Meridional Wind Vector at 10 m\n",
    "            U100 =       Zonal Wind vector at 100 m\n",
    "            V100 =       Meridional Wind vector at 100 m\n",
    "    \n",
    "    2. If Nroll<=1, column names in the output data frame have the form:\n",
    "            TARGETVAR U10 V10 U100 V100 YEAR DAYOFYEAR HOUR\n",
    "       and TARGETVAR, U10, V10, U100, V100 each have a subindex 1 ... 10 indicating zone id.\n",
    "       If Nroll>1, the structure is the same, but the U10, V10, U100, V100 columns are replaced\n",
    "       by rolling means over Nroll measurements, and the names are U10_rmX, V10_rmX, U100_rmX, \n",
    "       and V100_rmX, where X equals Nroll.\n",
    "    '''\n",
    "\n",
    "    # Read in the windmill data, parsing the third column as datetimes. Make a hierarchical\n",
    "    # index out of the timestamp and zone id columns.  Then drop the measurement ID column.\n",
    "    df0 = pd.read_csv(fname, header=0, parse_dates=[2], index_col=[2,1])\n",
    "    if not keepID: \n",
    "        df0 = df0.drop('ID', 1)\n",
    "        print('ID column dropped')\n",
    "    else:\n",
    "        print('ID column kept')\n",
    "        \n",
    "    # Unstack the inner level of the index. The index is thus reduced to the timestamp, and \n",
    "    # the zone ids become subcolumns within the existing columns. In other words, where in\n",
    "    # df0 there are 10 rows per time stamp, one for each zone id, in df1 there is only \n",
    "    # 1 row, which contains the measurements made at the given time stamp in all the zone ids.\n",
    "    df1 = df0.unstack()\n",
    "\n",
    "    # Put the timestamp index back as a dataframe column and verify that all delta-times are one hour.\n",
    "    df2              = df1.reset_index()\n",
    "    dtimes           = df2[\"TIMESTAMP\"] - df2[\"TIMESTAMP\"].shift(+1)\n",
    "    Ntimepoints      = len(df2)\n",
    "    Ndeltatimes1h    = dtimes[dtimes==np.timedelta64(1, 'h')].count()\n",
    "    assert (Ntimepoints == Ndeltatimes1h+1), 'Delta times not all equal to 1 h!'\n",
    "    print('Number of time points:                 {0}'.format(Ntimepoints))\n",
    "    print('Number of delta-times equal to 1 hour: {0}'.format(Ndeltatimes1h))\n",
    "    \n",
    "    # Remove duplicate wind measurements (5 is duplicate with 4, and 8 with 7)\n",
    "    nturbines         = 10\n",
    "    wind_measurements = [1, 2, 3, 4, 6, 7, 9, 10]\n",
    "    for i in range(1,nturbines+1):\n",
    "        if i not in wind_measurements:\n",
    "            df2 = df2.drop([(\"U10\",i), (\"V10\",i), (\"U100\",i), (\"V100\",i)], axis=1)\n",
    "    \n",
    "    # Add rolling means of the wind measurements and drop original measurements\n",
    "    if Nroll>1:\n",
    "        print('Computing rolling means over {0} measurements'.format(Nroll))\n",
    "        dname = \"_rm\"+str(Nroll)\n",
    "        for i in wind_measurements:\n",
    "            df2[(\"U10\"+dname,i)]  = df2[(\"U10\",i)].rolling(Nroll, min_periods=1).mean()\n",
    "            df2[(\"U100\"+dname,i)] = df2[(\"U100\",i)].rolling(Nroll, min_periods=1).mean()\n",
    "            df2[(\"V10\"+dname,i)]  = df2[(\"V10\",i)].rolling(Nroll, min_periods=1).mean()\n",
    "            df2[(\"V100\"+dname,i)] = df2[(\"V100\",i)].rolling(Nroll, min_periods=1).mean()\n",
    "        df2 = df2.drop([\"U10\", \"U100\", \"V10\", \"V100\"], axis=1, level=0)\n",
    "    else:\n",
    "        print('No rolling means computed')\n",
    "    \n",
    "    # Extract year, day of year, and hour from timestamp, then drop timestamp column\n",
    "    df2[\"YEAR\"]      = df2[\"TIMESTAMP\"].map(lambda x: x.year)\n",
    "    df2[\"DAYOFYEAR\"] = df2[\"TIMESTAMP\"].map(lambda x: x.timetuple().tm_yday)\n",
    "    df2[\"HOUR\"]      = df2[\"TIMESTAMP\"].map(lambda x: x.hour)\n",
    "    df2              = df2.drop('TIMESTAMP', axis=1, level=0)\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID column dropped\n",
      "Number of time points:                 13871\n",
      "Number of delta-times equal to 1 hour: 13870\n",
      "No rolling means computed\n",
      "\n",
      "Dataframe train_df:\n",
      "       TARGETVAR                                                              \\\n",
      "ZONEID         1         2         3         4         5         6         7   \n",
      "0       0.000000  0.596273  0.425465  0.378229  0.273678  0.268101  0.000000   \n",
      "1       0.054879  0.411180  0.363851  0.063012  0.086796  0.034542  0.014708   \n",
      "2       0.110234  0.167243  0.297129  0.036704  0.006811  0.020621  0.035098   \n",
      "3       0.165116  0.037326  0.235438  0.034342  0.018646  0.001867  0.045055   \n",
      "4       0.156940  0.051206  0.120904  0.033554  0.034812  0.015174  0.050160   \n",
      "\n",
      "                                ...       V100                                \\\n",
      "ZONEID         8    9        10 ...          2         3         4         6   \n",
      "0       0.000000  0.0  0.594361 ...  -7.101347 -6.221648 -4.486657 -2.956134   \n",
      "1       0.014954  0.0  0.569679 ...  -5.896778 -5.254089 -3.213752 -1.937051   \n",
      "2       0.071785  0.0  0.330539 ...  -4.489369 -4.163414 -2.418119 -1.260735   \n",
      "3       0.066796  0.0  0.211308 ...  -3.598824 -2.915458 -2.149654 -0.956475   \n",
      "4       0.034797  0.0  0.172140 ...  -3.244667 -2.689838 -1.991829 -0.691806   \n",
      "\n",
      "                                      YEAR DAYOFYEAR HOUR  \n",
      "ZONEID         7         9        10                       \n",
      "0       0.298533 -2.078063 -5.992232  2012         1    1  \n",
      "1       0.797498 -1.006914 -5.318086  2012         1    2  \n",
      "2       1.626758 -0.015490 -4.052232  2012         1    3  \n",
      "3       2.625774  0.823531 -2.913831  2012         1    4  \n",
      "4       3.501676  1.471102 -1.976100  2012         1    5  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "Training data frame saved to data/Train_pp_2017_04_17_21_52_33.pkl\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preprocess the training data set, output a pickle file.\n",
    "'''\n",
    "# Load and preprocess data\n",
    "train_csv = \"data/Train_O4UPEyW.csv\"\n",
    "train_df  = preProcess(train_csv, Nroll=1, keepID=False)\n",
    "print('\\nDataframe train_df:\\n%s' %train_df.head())\n",
    "\n",
    "# Output dataframe in pickle format\n",
    "train_fname = \"data/Train_pp_\" + strftime(\"%Y_%m_%d_%H_%M_%S\") + \".pkl\"\n",
    "try:\n",
    "    train_df.to_pickle(train_fname)\n",
    "    print('\\nTraining data frame saved to {0}'.format(train_fname))\n",
    "except:\n",
    "    print('\\nError saving training data frame to {0}'.format(train_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID column dropped\n",
      "Number of time points:                 13871\n",
      "Number of delta-times equal to 1 hour: 13870\n",
      "No rolling means computed\n",
      "\n",
      "Dataframe train_df:\n",
      "   TARGETVAR_1  TARGETVAR_2  TARGETVAR_3  TARGETVAR_4  TARGETVAR_5  \\\n",
      "0     0.000000     0.596273     0.425465     0.378229     0.273678   \n",
      "1     0.054879     0.411180     0.363851     0.063012     0.086796   \n",
      "2     0.110234     0.167243     0.297129     0.036704     0.006811   \n",
      "3     0.165116     0.037326     0.235438     0.034342     0.018646   \n",
      "4     0.156940     0.051206     0.120904     0.033554     0.034812   \n",
      "\n",
      "   TARGETVAR_6  TARGETVAR_7  TARGETVAR_8  TARGETVAR_9  TARGETVAR_10  ...   \\\n",
      "0     0.268101     0.000000     0.000000          0.0      0.594361  ...    \n",
      "1     0.034542     0.014708     0.014954          0.0      0.569679  ...    \n",
      "2     0.020621     0.035098     0.071785          0.0      0.330539  ...    \n",
      "3     0.001867     0.045055     0.066796          0.0      0.211308  ...    \n",
      "4     0.015174     0.050160     0.034797          0.0      0.172140  ...    \n",
      "\n",
      "     V100_2    V100_3    V100_4    V100_6    V100_7    V100_9   V100_10  YEAR  \\\n",
      "0 -7.101347 -6.221648 -4.486657 -2.956134  0.298533 -2.078063 -5.992232  2012   \n",
      "1 -5.896778 -5.254089 -3.213752 -1.937051  0.797498 -1.006914 -5.318086  2012   \n",
      "2 -4.489369 -4.163414 -2.418119 -1.260735  1.626758 -0.015490 -4.052232  2012   \n",
      "3 -3.598824 -2.915458 -2.149654 -0.956475  2.625774  0.823531 -2.913831  2012   \n",
      "4 -3.244667 -2.689838 -1.991829 -0.691806  3.501676  1.471102 -1.976100  2012   \n",
      "\n",
      "   DAYOFYEAR  HOUR  \n",
      "0          1     1  \n",
      "1          1     2  \n",
      "2          1     3  \n",
      "3          1     4  \n",
      "4          1     5  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "Training data frame saved to data/Train_pp_2017_03_27_17_47_52.feather\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preprocess the training data set in Feather format for notebooks running R kernel.\n",
    "'''\n",
    "# Load and preprocess data\n",
    "train_csv = \"data/Train_O4UPEyW.csv\"\n",
    "train_df  = preProcess(train_csv, Nroll=1, keepID=False)\n",
    "\n",
    "# Rename dataframe columns\n",
    "predictors  = [item[0]+'_'+str(item[1]) for item in train_df.columns.values if item[0]!='TARGETVAR']\n",
    "predictors  = [predictor if predictor[-1]!='_' else predictor[:-1] for predictor in predictors]\n",
    "targets     = [item[0]+'_'+str(item[1]) for item in train_df.columns.values if item[0]=='TARGETVAR']\n",
    "train_df.columns = targets+predictors\n",
    "print('\\nDataframe train_df:\\n%s' %train_df.head())\n",
    "\n",
    "# Output data frame in feather format\n",
    "train_fname = \"data/Train_pp_\" + strftime(\"%Y_%m_%d_%H_%M_%S\") + \".feather\"\n",
    "try:\n",
    "    feather.write_dataframe(train_df, train_fname)\n",
    "    print('\\nTraining data frame saved to {0}'.format(train_fname))\n",
    "except:\n",
    "    print('\\nError saving training data frame to {0}'.format(train_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID column kept\n",
      "Number of time points:                 2929\n",
      "Number of delta-times equal to 1 hour: 2928\n",
      "No rolling means computed\n",
      "\n",
      "Dataframe test_df:\n",
      "              ID                                                              \\\n",
      "ZONEID         1         2         3         4         5         6         7   \n",
      "0       30010001  30010002  30010003  30010004  30010005  30010006  30010007   \n",
      "1       30010101  30010102  30010103  30010104  30010105  30010106  30010107   \n",
      "2       30010201  30010202  30010203  30010204  30010205  30010206  30010207   \n",
      "3       30010301  30010302  30010303  30010304  30010305  30010306  30010307   \n",
      "4       30010401  30010402  30010403  30010404  30010405  30010406  30010407   \n",
      "\n",
      "                                     ...       V100                      \\\n",
      "ZONEID         8         9        10 ...          2         3         4   \n",
      "0       30010008  30010009  30010010 ...  -5.077052 -4.559475 -2.754384   \n",
      "1       30010108  30010109  30010110 ...  -5.350381 -5.098012 -2.039563   \n",
      "2       30010208  30010209  30010210 ...  -5.587994 -5.242004 -2.112832   \n",
      "3       30010308  30010309  30010310 ...  -5.364627 -5.389050 -2.391150   \n",
      "4       30010408  30010409  30010410 ...  -5.191124 -5.500988 -2.484262   \n",
      "\n",
      "                                                YEAR DAYOFYEAR HOUR  \n",
      "ZONEID         6         7         9        10                       \n",
      "0      -3.287274 -6.763927 -5.748985 -4.277716  2013       213    0  \n",
      "1      -2.081795 -7.279274 -5.847995 -5.323414  2013       213    1  \n",
      "2      -2.149975 -7.343893 -6.058642 -6.176686  2013       213    2  \n",
      "3      -2.497491 -7.275712 -5.923299 -6.710426  2013       213    3  \n",
      "4      -2.632834 -7.140369 -5.934493 -6.825925  2013       213    4  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "Testing data frame saved to data/Test_pp_2017_03_28_18_05_11.pkl\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preprocess the testing data set, output a pickle file.\n",
    "'''\n",
    "test_csv  = \"data/Test_uP7dymh.csv\"\n",
    "\n",
    "test_df = preProcess(test_csv, Nroll=1, keepID=True)\n",
    "print('\\nDataframe test_df:\\n%s' %test_df.head())\n",
    "\n",
    "test_fname = \"data/Test_pp_\" + strftime(\"%Y_%m_%d_%H_%M_%S\") + \".pkl\"\n",
    "try:\n",
    "    test_df.to_pickle(test_fname)\n",
    "    print('\\nTesting data frame saved to {0}'.format(test_fname))\n",
    "except:\n",
    "    print('\\nError saving testing data frame to {0}'.format(test_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell6'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID column kept\n",
      "Number of time points:                 2929\n",
      "Number of delta-times equal to 1 hour: 2928\n",
      "No rolling means computed\n",
      "\n",
      "Dataframe test_df:\n",
      "       ID_1      ID_2      ID_3      ID_4      ID_5      ID_6      ID_7  \\\n",
      "0  30010001  30010002  30010003  30010004  30010005  30010006  30010007   \n",
      "1  30010101  30010102  30010103  30010104  30010105  30010106  30010107   \n",
      "2  30010201  30010202  30010203  30010204  30010205  30010206  30010207   \n",
      "3  30010301  30010302  30010303  30010304  30010305  30010306  30010307   \n",
      "4  30010401  30010402  30010403  30010404  30010405  30010406  30010407   \n",
      "\n",
      "       ID_8      ID_9     ID_10  ...     V100_2    V100_3    V100_4    V100_6  \\\n",
      "0  30010008  30010009  30010010  ...  -5.077052 -4.559475 -2.754384 -3.287274   \n",
      "1  30010108  30010109  30010110  ...  -5.350381 -5.098012 -2.039563 -2.081795   \n",
      "2  30010208  30010209  30010210  ...  -5.587994 -5.242004 -2.112832 -2.149975   \n",
      "3  30010308  30010309  30010310  ...  -5.364627 -5.389050 -2.391150 -2.497491   \n",
      "4  30010408  30010409  30010410  ...  -5.191124 -5.500988 -2.484262 -2.632834   \n",
      "\n",
      "     V100_7    V100_9   V100_10  YEAR  DAYOFYEAR  HOUR  \n",
      "0 -6.763927 -5.748985 -4.277716  2013        213     0  \n",
      "1 -7.279274 -5.847995 -5.323414  2013        213     1  \n",
      "2 -7.343893 -6.058642 -6.176686  2013        213     2  \n",
      "3 -7.275712 -5.923299 -6.710426  2013        213     3  \n",
      "4 -7.140369 -5.934493 -6.825925  2013        213     4  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "Testing data frame saved to data/Test_pp_2017_03_28_14_13_10.feather\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preprocess the testing data set in Feather format for notebooks running R kernel.\n",
    "'''\n",
    "test_csv  = \"data/Test_uP7dymh.csv\"\n",
    "\n",
    "test_df = preProcess(test_csv, Nroll=0, keepID=True)\n",
    "\n",
    "# Rename dataframe columns\n",
    "predictors  = [item[0]+'_'+str(item[1]) for item in test_df.columns.values]\n",
    "predictors  = [predictor if predictor[-1]!='_' else predictor[:-1] for predictor in predictors]\n",
    "test_df.columns = predictors\n",
    "print('\\nDataframe test_df:\\n%s' %test_df.head())\n",
    "    \n",
    "# Output data frame in feather format\n",
    "test_fname = \"data/Test_pp_\" + strftime(\"%Y_%m_%d_%H_%M_%S\") + \".feather\"\n",
    "try:\n",
    "    feather.write_dataframe(test_df, test_fname)\n",
    "    print('\\nTesting data frame saved to {0}'.format(test_fname))\n",
    "except:\n",
    "    print('\\nError saving testing data frame to {0}'.format(test_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell7'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID column dropped\n",
      "Number of time points:                 2929\n",
      "Number of delta-times equal to 1 hour: 2928\n",
      "Computing rolling means over 3 measurements\n",
      "\n",
      "Dataframe solution_df for pickle:\n",
      "       TARGETVAR                                                              \\\n",
      "ZONEID         1         2         3         4         5         6         7   \n",
      "0       0.000000  0.270840  0.070839  0.032609  0.029816  0.052044  0.140550   \n",
      "1       0.019168  0.195737  0.081343  0.028040  0.041659  0.051252  0.152884   \n",
      "2       0.286627  0.207469  0.107185  0.064430  0.052353  0.086763  0.199029   \n",
      "3       0.287943  0.395594  0.157022  0.055293  0.052712  0.103719  0.281050   \n",
      "4       0.352317  0.509844  0.188443  0.143825  0.089402  0.111278  0.307617   \n",
      "\n",
      "                                     ...   U100_rm3   V10_rm3  V100_rm3  \\\n",
      "ZONEID         8         9        10 ...          9         9         9   \n",
      "0       0.224602  0.054787  0.121128 ...   1.473541 -3.757118 -5.748985   \n",
      "1       0.150140  0.184262  0.235245 ...   2.425901 -3.923264 -5.798490   \n",
      "2       0.151965  0.389327  0.271003 ...   2.899162 -4.043484 -5.885207   \n",
      "3       0.217666  0.503941  0.272300 ...   3.475966 -4.194771 -5.943312   \n",
      "4       0.312690  0.389198  0.331207 ...   3.356855 -4.239347 -5.972145   \n",
      "\n",
      "         U10_rm3  U100_rm3   V10_rm3  V100_rm3  YEAR DAYOFYEAR HOUR  \n",
      "ZONEID        10        10        10        10                       \n",
      "0      -0.165117  0.320843 -2.658255 -4.277716  2013       213    0  \n",
      "1      -0.257103 -0.014866 -3.223966 -4.800565  2013       213    1  \n",
      "2       0.085075  0.330257 -3.693685 -5.259272  2013       213    2  \n",
      "3       0.764744  1.048942 -4.490173 -6.070175  2013       213    3  \n",
      "4       1.679930  2.239443 -4.925310 -6.571012  2013       213    4  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "Solution data frame saved to data/Solution_pp_2017_04_23_23_11_23.pkl\n",
      "\n",
      "Dataframe solution_df for feather:\n",
      "   TARGETVAR_1  TARGETVAR_2  TARGETVAR_3  TARGETVAR_4  TARGETVAR_5  \\\n",
      "0     0.000000     0.270840     0.070839     0.032609     0.029816   \n",
      "1     0.019168     0.195737     0.081343     0.028040     0.041659   \n",
      "2     0.286627     0.207469     0.107185     0.064430     0.052353   \n",
      "3     0.287943     0.395594     0.157022     0.055293     0.052712   \n",
      "4     0.352317     0.509844     0.188443     0.143825     0.089402   \n",
      "\n",
      "   TARGETVAR_6  TARGETVAR_7  TARGETVAR_8  TARGETVAR_9  TARGETVAR_10  ...   \\\n",
      "0     0.052044     0.140550     0.224602     0.054787      0.121128  ...    \n",
      "1     0.051252     0.152884     0.150140     0.184262      0.235245  ...    \n",
      "2     0.086763     0.199029     0.151965     0.389327      0.271003  ...    \n",
      "3     0.103719     0.281050     0.217666     0.503941      0.272300  ...    \n",
      "4     0.111278     0.307617     0.312690     0.389198      0.331207  ...    \n",
      "\n",
      "   U100_rm3_9  V10_rm3_9  V100_rm3_9  U10_rm3_10  U100_rm3_10  V10_rm3_10  \\\n",
      "0    1.473541  -3.757118   -5.748985   -0.165117     0.320843   -2.658255   \n",
      "1    2.425901  -3.923264   -5.798490   -0.257103    -0.014866   -3.223966   \n",
      "2    2.899162  -4.043484   -5.885207    0.085075     0.330257   -3.693685   \n",
      "3    3.475966  -4.194771   -5.943312    0.764744     1.048942   -4.490173   \n",
      "4    3.356855  -4.239347   -5.972145    1.679930     2.239443   -4.925310   \n",
      "\n",
      "   V100_rm3_10  YEAR  DAYOFYEAR  HOUR  \n",
      "0    -4.277716  2013        213     0  \n",
      "1    -4.800565  2013        213     1  \n",
      "2    -5.259272  2013        213     2  \n",
      "3    -6.070175  2013        213     3  \n",
      "4    -6.571012  2013        213     4  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "Solution data frame saved to data/Solution_pp_2017_04_23_23_11_23.feather\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preprocess the solution file. This is the testing data set with TARGETVAR included.\n",
    "Preprocess it in the same way as the training data set, then output it in pickle and feather formats.\n",
    "'''\n",
    "# Load and preprocess data\n",
    "solution_csv = \"data/Solution.csv\"\n",
    "solution_df  = preProcess(solution_csv, Nroll=3, keepID=False)\n",
    "print('\\nDataframe solution_df for pickle:\\n%s' %solution_df.head())\n",
    "\n",
    "# Output dataframe in pickle format\n",
    "fname          = strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "solution_fname = \"data/Solution_pp_\" + fname + \".pkl\"\n",
    "try:\n",
    "    solution_df.to_pickle(solution_fname)\n",
    "    print('\\nSolution data frame saved to {0}'.format(solution_fname))\n",
    "except:\n",
    "    print('\\nError saving solution data frame to {0}'.format(solution_fname))\n",
    "    \n",
    "\n",
    "# Rename dataframe columns for easier handling in R\n",
    "fields  = [item[0]+'_'+str(item[1]) for item in solution_df.columns.values]\n",
    "fields  = [field if field[-1]!='_' else field[:-1] for field in fields]\n",
    "solution_df.columns = fields\n",
    "print('\\nDataframe solution_df for feather:\\n%s' %solution_df.head())\n",
    "    \n",
    "# Output data frame in feather format\n",
    "solution_fname = \"data/Solution_pp_\" + fname + \".feather\"\n",
    "try:\n",
    "    feather.write_dataframe(solution_df, solution_fname)\n",
    "    print('\\nSolution data frame saved to {0}'.format(solution_fname))\n",
    "except:\n",
    "    print('\\nError saving solution data frame to {0}'.format(solution_fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
