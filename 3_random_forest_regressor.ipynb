{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Wind Turbine Output with a Random Forest\n",
    "\n",
    "In this analysis, the shape of the data frame is taken directly from the original data file: each record contains measurements from a single zone, even though the power output from the wind turbine in that zone is correlated with wind velocity measurements in other zones.\n",
    "\n",
    "1. [Imports.](#Cell1)\n",
    "1. [Data preprocessing function for training and testing data sets.](#Cell2)\n",
    "1. [Preprocess training data set and split it into training and testing subsets.](#Cell3)\n",
    "1. [Fit random forest model to training subset of training data set.](#Cell4)\n",
    "1. [Do a grid search to find optimal hyper-parameters of the random forest regressor.](#Cell5)\n",
    "1. [Evaluate fit results.](#Cell6)\n",
    "1. [Fit random forest model to entire training data set.](#Cell7)\n",
    "1. [Prepare test data set in the same way as the training set, make predictions, and create output csv file.](#Cell8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Imports\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "import csv\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data preprocessing function for training and testing data sets.\n",
    "'''\n",
    "\n",
    "def PreProcess(fname):\n",
    "    '''\n",
    "    Read in wind turbine data and store them in a Pandas dataframe after cleanup.\n",
    "    The input csv file fname contains the following fields:\n",
    "\n",
    "    ID:         Unique ID for each observation\n",
    "    ZONEID:     Zone/Turbine ID, a number between 1 and 10\n",
    "    TIMESTAMP:  Time of observation, in the format \"YYYYMMDD h:mm\" or \"YYYYMMDD hh:mm\"\n",
    "    TARGETVAR:  Wind turbine output\n",
    "    U10:        Zonal Wind Vector at 10 m\n",
    "    V10:        Meridional Wind Vector at 10 m\n",
    "    U100:       Zonal Wind vector at 100 m\n",
    "    V100:       Meridional Wind vector at 100 m\n",
    "    '''\n",
    "\n",
    "    # Read in the windmill data, parsing the third column as datetimes.\n",
    "    Train            = \"Train\" in fname\n",
    "    df0              = pd.read_csv(fname, header=0, parse_dates=[2])\n",
    "\n",
    "    # Extract year, day of year, and hour from timestamp, then drop timestamp column\n",
    "    df0[\"Year\"]      = df0[\"TIMESTAMP\"].map(lambda x: x.year)\n",
    "    df0[\"DayOfYear\"] = df0[\"TIMESTAMP\"].map(lambda x: x.timetuple().tm_yday)\n",
    "    df0[\"Hour\"]      = df0[\"TIMESTAMP\"].map(lambda x: x.hour)\n",
    "    df0              = df0.drop('TIMESTAMP', axis=1)\n",
    "\n",
    "    # Rename columns\n",
    "    if Train:\n",
    "        df0.rename(columns={\"ID\": \"Id\", \"ZONEID\": \"ZoneId\", \"TARGETVAR\": \"Target\"}, inplace=True)\n",
    "    else:\n",
    "        df0.rename(columns={\"ID\": \"Id\", \"ZONEID\": \"ZoneId\"}, inplace=True)\n",
    "\n",
    "    # Convert categorical variables in dataframe.\n",
    "    df0['ZoneId']    = df0['ZoneId'].astype(int).astype(\"category\")\n",
    "    df0              = pd.get_dummies(df0, drop_first=True)\n",
    "\n",
    "    print('PreProcess: Dataframe Shape = {0}'.format(df0.shape))\n",
    "    \n",
    "    return df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreProcess: Dataframe Shape = (138710, 18)\n",
      "Size of data set for training: 97097, for testing: 41613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preprocess training data set and split it into training and testing subsets.\n",
    "'''\n",
    "\n",
    "fname = \"data/Train_O4UPEyW.csv\"\n",
    "df0   = PreProcess(fname)\n",
    "\n",
    "# Convert pandas dataframe to its numpy representation, separating out features from target variable.\n",
    "features  = df0.columns.values.tolist()\n",
    "features.remove(\"Target\")\n",
    "features.remove(\"Id\")\n",
    "X         = df0.as_matrix(columns=features)\n",
    "y         = np.array(df0[\"Target\"].tolist())\n",
    "\n",
    "# Create training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print('Size of data set for training: {0}, for testing: {1}\\n'.format(len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 43s, sys: 4.28 s, total: 5min 47s\n",
      "Wall time: 1min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=30,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=5,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=1000, n_jobs=-1, oob_score=False, random_state=0,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Fit random forest model to training subset of training data set.\n",
    "'''\n",
    "\n",
    "rfr_train = RandomForestRegressor(n_estimators=1000, criterion=\"mse\", max_depth=30, min_samples_split=2, \n",
    "                                  min_samples_leaf=5, max_features=\"sqrt\", max_leaf_nodes=None, bootstrap=True,\n",
    "                                  oob_score=False, n_jobs=-1, random_state=0, verbose=0)\n",
    "%time rfr_train.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21h 26min 45s, sys: 18min 34s, total: 21h 45min 20s\n",
      "Wall time: 5h 58min 48s\n",
      "Best parameter values found on development set:\n",
      " \n",
      "{'n_estimators': 2000, 'max_depth': 40, 'min_samples_leaf': 3}\n",
      " \n",
      "Grid scores on development set:\n",
      " \n",
      "0.02116 (+/-0.00064) for {'n_estimators': 1000, 'max_depth': 30, 'min_samples_leaf': 3}\n",
      "0.02115 (+/-0.00065) for {'n_estimators': 2000, 'max_depth': 30, 'min_samples_leaf': 3}\n",
      "0.02115 (+/-0.00064) for {'n_estimators': 3000, 'max_depth': 30, 'min_samples_leaf': 3}\n",
      "0.02199 (+/-0.00066) for {'n_estimators': 1000, 'max_depth': 30, 'min_samples_leaf': 5}\n",
      "0.02198 (+/-0.00066) for {'n_estimators': 2000, 'max_depth': 30, 'min_samples_leaf': 5}\n",
      "0.02198 (+/-0.00066) for {'n_estimators': 3000, 'max_depth': 30, 'min_samples_leaf': 5}\n",
      "0.02259 (+/-0.00068) for {'n_estimators': 1000, 'max_depth': 30, 'min_samples_leaf': 7}\n",
      "0.02259 (+/-0.00069) for {'n_estimators': 2000, 'max_depth': 30, 'min_samples_leaf': 7}\n",
      "0.02259 (+/-0.00069) for {'n_estimators': 3000, 'max_depth': 30, 'min_samples_leaf': 7}\n",
      "0.02114 (+/-0.00065) for {'n_estimators': 1000, 'max_depth': 40, 'min_samples_leaf': 3}\n",
      "0.02114 (+/-0.00066) for {'n_estimators': 2000, 'max_depth': 40, 'min_samples_leaf': 3}\n",
      "0.02114 (+/-0.00065) for {'n_estimators': 3000, 'max_depth': 40, 'min_samples_leaf': 3}\n",
      "0.02198 (+/-0.00066) for {'n_estimators': 1000, 'max_depth': 40, 'min_samples_leaf': 5}\n",
      "0.02198 (+/-0.00066) for {'n_estimators': 2000, 'max_depth': 40, 'min_samples_leaf': 5}\n",
      "0.02198 (+/-0.00067) for {'n_estimators': 3000, 'max_depth': 40, 'min_samples_leaf': 5}\n",
      "0.02259 (+/-0.00069) for {'n_estimators': 1000, 'max_depth': 40, 'min_samples_leaf': 7}\n",
      "0.02259 (+/-0.00069) for {'n_estimators': 2000, 'max_depth': 40, 'min_samples_leaf': 7}\n",
      "0.02259 (+/-0.00069) for {'n_estimators': 3000, 'max_depth': 40, 'min_samples_leaf': 7}\n",
      "0.02114 (+/-0.00064) for {'n_estimators': 1000, 'max_depth': 50, 'min_samples_leaf': 3}\n",
      "0.02114 (+/-0.00065) for {'n_estimators': 2000, 'max_depth': 50, 'min_samples_leaf': 3}\n",
      "0.02114 (+/-0.00064) for {'n_estimators': 3000, 'max_depth': 50, 'min_samples_leaf': 3}\n",
      "0.02198 (+/-0.00066) for {'n_estimators': 1000, 'max_depth': 50, 'min_samples_leaf': 5}\n",
      "0.02198 (+/-0.00066) for {'n_estimators': 2000, 'max_depth': 50, 'min_samples_leaf': 5}\n",
      "0.02198 (+/-0.00067) for {'n_estimators': 3000, 'max_depth': 50, 'min_samples_leaf': 5}\n",
      "0.02259 (+/-0.00069) for {'n_estimators': 1000, 'max_depth': 50, 'min_samples_leaf': 7}\n",
      "0.02259 (+/-0.00069) for {'n_estimators': 2000, 'max_depth': 50, 'min_samples_leaf': 7}\n",
      "0.02259 (+/-0.00069) for {'n_estimators': 3000, 'max_depth': 50, 'min_samples_leaf': 7}\n",
      "\n",
      "Best estimator:\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=40,\n",
      "           max_features='sqrt', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=3,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=2000, n_jobs=-1, oob_score=False, random_state=0,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "Random forest regression model saved to fitted_models/rfr_train_2017_04_07_00_31_00.model\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Do a grid search to find optimal hyper-parameters of the random forest regressor.\n",
    "Use Root Mean Squared Error (RMSE) to score parameter choices.\n",
    "\n",
    "(This cell can be omitted if the previous one was run.)\n",
    "'''\n",
    "\n",
    "# Specify the parameter grid to be searched\n",
    "parameter_grid = [{'n_estimators': [1000, 2000, 3000], \n",
    "                   'max_depth': [30, 40, 50], \n",
    "                   'min_samples_leaf': [3, 5, 7]}]\n",
    "\n",
    "# Start the grid search\n",
    "rfo = GridSearchCV(RandomForestRegressor(criterion='mse', min_samples_split=2, max_features=\"sqrt\",\n",
    "                                         max_leaf_nodes=None, bootstrap=True, oob_score=False, \n",
    "                                         n_jobs=-1, random_state=0, verbose=0),\n",
    "                   parameter_grid, refit=True, cv=5, scoring='neg_mean_squared_error')\n",
    "%time rfo.fit(X_train, y_train)\n",
    "\n",
    "# Print out the results (flipping the sign on the grid scores to make them positive again).\n",
    "print(\"Best parameter values found on development set:\")\n",
    "print(\" \")\n",
    "print(rfo.best_params_)\n",
    "print(\" \")\n",
    "print(\"Grid scores on development set:\")\n",
    "print(\" \")\n",
    "for mean_score, std_score, settings in zip(rfo.cv_results_['mean_test_score'], \n",
    "                                           rfo.cv_results_['std_test_score'],\n",
    "                                           rfo.cv_results_['params']):\n",
    "    print(\"%0.5f (+/-%0.05f) for %r\" %(-mean_score, 2*std_score, settings))\n",
    "\n",
    "# Retrieve best random forest model from grid search\n",
    "rfr_train = rfo.best_estimator_\n",
    "print(\"\\nBest estimator:\\n%s\" %rfr_train)\n",
    "\n",
    "fName = 'rfr_train_' + strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "path_to_file = 'fitted_models/'+fName+'.model'\n",
    "joblib.dump(rfr_train, path_to_file)\n",
    "print('\\nRandom forest regression model saved to {0}'.format(path_to_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell6'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "\n",
      "         V100: 0.249530\n",
      "         U100: 0.229922\n",
      "          V10: 0.183493\n",
      "          U10: 0.173526\n",
      "    DayOfYear: 0.040154\n",
      "         Hour: 0.036495\n",
      "    ZoneId_10: 0.019304\n",
      "     ZoneId_3: 0.012043\n",
      "     ZoneId_6: 0.010053\n",
      "     ZoneId_5: 0.009071\n",
      "     ZoneId_4: 0.007283\n",
      "     ZoneId_8: 0.006840\n",
      "     ZoneId_7: 0.006761\n",
      "     ZoneId_2: 0.006053\n",
      "         Year: 0.004861\n",
      "     ZoneId_9: 0.004610\n",
      "\n",
      "RMSE on train data set: 0.112916130391\n",
      "RMSE on test data set:  0.14669382404\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Evaluate fit results.\n",
    "'''\n",
    "FeatureImportances = [[feature, importance] for (feature,importance) in zip(features,rfr_train.feature_importances_)]\n",
    "print('Feature Importances:\\n')\n",
    "for fi in sorted(FeatureImportances, key=lambda x: x[1], reverse=True):\n",
    "    print('   %10s: %f' %(fi[0],fi[1]))\n",
    "\n",
    "y_train_pred = rfr_train.predict(X_train)\n",
    "y_test_pred  = rfr_train.predict(X_test)\n",
    "rmse_train   = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "rmse_test    = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print('\\nRMSE on train data set: {0}'.format(rmse_train))\n",
    "print('RMSE on test data set:  {0}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell7'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 59s, sys: 4.39 s, total: 7min 3s\n",
      "Wall time: 1min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=30,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=5,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=1000, n_jobs=-1, oob_score=False, random_state=0,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Fit random forest model to entire training data set.\n",
    "'''\n",
    "settings = rfr_train.get_params()\n",
    "rfr      = RandomForestRegressor(**settings)\n",
    "%time rfr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell8'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreProcess: Dataframe Shape = (29290, 17)\n",
      "\n",
      "Total number of observation times in test set:       29290\n",
      "Number of observations in August and September 2013: 14640\n",
      "\n",
      "Output written to data/rfr_2017_04_08_21_31_35.out.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Prepare test data set in the same way as the training set, make predictions, and create output csv file.\n",
    "'''\n",
    "\n",
    "# Preprocess testing data set.\n",
    "fname       = \"data/Test_uP7dymh.csv\"\n",
    "ttdf0       = PreProcess(fname)\n",
    "\n",
    "# Save Id column to list.\n",
    "ttid        = ttdf0['Id'].tolist()\n",
    "\n",
    "# Count how many observations we have in August and September 2013\n",
    "nTotal      = len(ttdf0)\n",
    "nAugSep2013 = len([DoY for DoY in ttdf0['DayOfYear'] if DoY>212 and DoY<274])\n",
    "print('\\nTotal number of observation times in test set:       {0}'.format(nTotal))\n",
    "print('Number of observations in August and September 2013: {0}'.format(nAugSep2013))\n",
    "\n",
    "# Compute predictions for test set.\n",
    "ttX         = ttdf0.as_matrix(columns=features)\n",
    "tty         = rfr.predict(ttX)\n",
    "\n",
    "# Generate output csv file\n",
    "fName_out   = 'data/rfr_' + strftime(\"%Y_%m_%d_%H_%M_%S\") + '.out.csv'\n",
    "with open(fName_out, 'w') as csvfile:\n",
    "    writer  = csv.writer(csvfile)\n",
    "    writer.writerow([\"ID\", \"TARGETVAR\"])\n",
    "    for idval,yval in zip(ttid,tty):\n",
    "        writer.writerow([idval,yval])\n",
    "print('\\nOutput written to {0}'.format(fName_out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
