{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution Checker for H2O July 2016 NYC Hackathon\n",
    "\n",
    "1. [Create solutions file data/newSolution.csv, with the target variable values for the test set.](#Cell1)\n",
    "1. [Check predictions for public and private leader boards.](#Cell2)\n",
    "\n",
    "### Notes:\n",
    "\n",
    "The full wind turbine data set, including the target variable values for the test set,\n",
    "is available from Dr. Tao Hong's blog at http://blog.drhongtao.com/. Look for the \n",
    "GEFCom2014 data set. If it's not available from the blog it may be downloadable \n",
    "via the publications page, http://www.drhongtao.com/publications.\n",
    "\n",
    "To extract the relevant data, do:\n",
    "```\n",
    "unzip GEFCom2014.zip\n",
    "cd GEFCom2014\\ Data/\n",
    "unzip GEFCom2014-W_V2.zip\n",
    "cd Wind/Task\\ 15/\n",
    "unzip Task15_W_Zone1_10.zip\n",
    "cd Task15_W_Zone1_10/\n",
    "```\n",
    "The files in this last directory are of the form \"Task15_W_ZoneN.csv\", where N is a\n",
    "number between 1 and 10. These files contain the full wind turbine data. \n",
    "\n",
    "The first cell below assumes we are sitting in the directory just above the data subdirectory, \n",
    "where GEFCom2014.zip was unzipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing target values: 81\n",
      "\n",
      "For zone ID 1: ['20130815 16:00', '20130920 4:00', '20131022 2:00', '20131101 1:00']\n",
      "For zone ID 2: ['20130920 4:00', '20131030 21:00', '20131101 1:00', '20131101 16:00', '20131102 23:00']\n",
      "For zone ID 3: ['20130807 5:00', '20130808 4:00', '20130808 5:00', '20130808 6:00', '20130808 7:00', '20130808 8:00', '20130808 9:00', '20130824 4:00', '20130824 5:00', '20130824 6:00', '20130826 5:00', '20130826 6:00', '20130826 7:00', '20130826 8:00', '20130826 9:00', '20130826 10:00', '20130826 11:00', '20130826 12:00', '20130826 13:00', '20130826 14:00', '20130826 15:00', '20130830 16:00', '20130830 17:00', '20130830 18:00', '20130901 16:00', '20130901 17:00', '20130901 18:00', '20130901 19:00', '20130901 20:00', '20130901 21:00', '20130901 22:00', '20130901 23:00', '20130902 0:00', '20130902 1:00', '20130902 2:00', '20130902 3:00', '20130902 4:00', '20130902 5:00', '20130902 6:00', '20130902 7:00', '20130902 8:00', '20130902 9:00', '20130902 10:00', '20130902 11:00', '20130905 2:00', '20130908 0:00', '20130908 1:00', '20130908 2:00', '20130908 3:00', '20130908 4:00', '20130908 5:00', '20130908 6:00', '20130908 7:00', '20130913 23:00', '20130914 2:00', '20130914 3:00', '20130914 4:00', '20130914 7:00', '20130914 9:00', '20130914 10:00', '20130914 13:00', '20130916 13:00', '20130916 14:00', '20130916 15:00', '20130916 16:00', '20130916 17:00', '20130916 18:00', '20130917 2:00', '20130917 17:00', '20130917 18:00', '20130917 20:00', '20131107 1:00']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create solutions file data/newSolution.csv, with the target variable values for the test set.\n",
    "'''\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "path = \"data/GEFCom2014 Data/Wind/Task 15/Task15_W_Zone1_10/\"\n",
    "dt1  = datetime.datetime.strptime(\"2013-08-01 00:00\", \"%Y-%m-%d %H:%M\")\n",
    "dt2  = datetime.datetime.strptime(\"2013-12-01 00:00\", \"%Y-%m-%d %H:%M\")\n",
    "\n",
    "missing_values = []\n",
    "with open('data/newSolution.csv', 'wb') as ofile:\n",
    "    ofwriter = csv.writer(ofile)\n",
    "    ofwriter.writerow(['ID', 'ZONEID', 'TIMESTAMP', 'TARGETVAR', 'U10', 'V10', 'U100', 'V100'])\n",
    "    for zoneid in range(1,11):\n",
    "        ifname = path+\"Task15_W_Zone\"+str(zoneid)+\".csv\"\n",
    "        with open(ifname, 'rb') as ifile:\n",
    "            ifreader = csv.reader(ifile)\n",
    "            next(ifreader)\n",
    "            for row in ifreader:\n",
    "                dt = datetime.datetime.strptime(row[1], \"%Y%m%d %H:%M\")\n",
    "                if dt>=dt1 and dt<=dt2:\n",
    "                    newrow = [zoneid+100*dt.hour+10000*dt.day+(22+dt.month)*1000000]\n",
    "                    try:\n",
    "                        targetvar = round(float(row[2]),9)\n",
    "                    except:\n",
    "                        targetvar = \"NA\"\n",
    "                        missing_values.append([zoneid,row[1]])\n",
    "                    newrow.extend([row[0],row[1],targetvar])\n",
    "                    newrow.extend([round(float(row[i]),9) for i in range(3,7)])\n",
    "                    ofwriter.writerow(newrow)\n",
    "n_missing = len(missing_values)\n",
    "print('Number of missing target values: %i\\n' %n_missing)\n",
    "for zoneid in range(1,11):\n",
    "    missing = [dtval for [ind,dtval] in missing_values if ind==zoneid]\n",
    "    if len(missing)>0:\n",
    "        print('For zone ID %i: %s' %(zoneid,missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad records in public solution: 74, in private solution: 7\n",
      "\n",
      "Public Leader Board:  RMSE = 0.171176576829, Predictions included: 14566\n",
      "Private Leader Board: RMSE = 0.176823739958, Predictions included: 14643\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Check predictions for public and private leader boards.\n",
    "'''\n",
    "import csv\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "#prediction_file = 'data/turbineOutputs10.csv'\n",
    "#prediction_file = 'data/turbineOutputsTest03.csv'\n",
    "#prediction_file = 'data/turbineOutputsTest04.csv'\n",
    "#prediction_file = 'data/xgb_out_2017_03_02_16_26_42.csv'\n",
    "#prediction_file = 'data/xgb_out_2017_03_04_16_12_45.csv'\n",
    "#prediction_file = 'data/xgb_out_2017_03_05_10_24_03.csv'\n",
    "#prediction_file = 'data/xgb_2017_03_05_17_57_26.out.csv'\n",
    "#prediction_file = 'data/xgbc_2017_03_06_13_07_26.out.csv'\n",
    "#prediction_file = 'data/xgbc_2017_03_08_17_42_23.out.csv'\n",
    "#prediction_file = 'data/xgbc_2017_03_08_17_59_12.out.csv'\n",
    "#prediction_file = 'data/xgbr_2017_03_12_10_32_47.out.csv' # rm=2\n",
    "#prediction_file = 'data/xgb_2017_03_10_06_48_40.out.csv' # With rolling average over 3 measurements\n",
    "#prediction_file = 'data/xgbr_2017_03_10_22_16_39.out.csv' # With rolling average over 3 measurements\n",
    "#prediction_file = 'data/xgbrc_2017_03_11_02_04_14.out.csv' # rm=3 plus classifier correction\n",
    "#prediction_file = 'data/xgbr_2017_03_11_10_49_07.out.csv' # rm=4\n",
    "#prediction_file = 'data/rfr_2017_03_15_17_03_01.out.csv'\n",
    "#prediction_file = 'data/xgbr_2017_03_28_09_06_00.out.csv' # rm=3, dups removed\n",
    "#prediction_file = 'data/gamr_2017_03_28_16_15_35.out.csv' # gamlss predictions with rm=3\n",
    "#prediction_file = 'data/gamr_2017_03_28_17_38_19.out.csv' # gamlss predictions with rm=3, predictor p-value>5%\n",
    "#prediction_file = 'data/xgbr_2017_03_29_05_22_41.out.csv' # rm=3, dups removed, (U,V,time) replaced by (H)\n",
    "#prediction_file = 'data/xgbrc_2017_04_04_02_23_28.out.csv' # rm=3, dups removed, classifier correction\n",
    "#prediction_file = 'data/xgbrc_2017_04_04_11_20_24.out.csv' # rm=3, dups removed, class corr T=0.001\n",
    "#prediction_file = 'data/xgbrc_2017_04_04_11_23_18.out.csv' # rm=3, dups removed, class corr T=0.0001\n",
    "#prediction_file = 'data/xgbrc_2017_04_04_11_26_43.out.csv' # rm=3, dups removed, class corr T=0.0\n",
    "#prediction_file = 'data/xgbrc_2017_04_04_11_37_56.out.csv' # rm=3, dups removed, class corr T=0.0, except. Turb 4\n",
    "#prediction_file = 'data/rfr_2017_04_04_15_51_02.out.csv' # random forest, rm=3, dups removed\n",
    "#prediction_file = 'data/rfr_2017_04_04_22_37_40.out.csv' # rfr, rm=3, dups removed\n",
    "#prediction_file = 'data/rfr_2017_04_04_22_49_03.out.csv' # rfr, rm=1\n",
    "#prediction_file = 'data/rfr_2017_04_04_23_41_57.out.csv' # Initial rfr notebook\n",
    "#prediction_file = 'data/rfr_2017_04_05_16_34_41.out.csv' # Initial rfr notebook, refactored\n",
    "#prediction_file = 'data/rfr_2017_04_05_23_21_53.out.csv' # Initial rfr notebook, refactored\n",
    "#prediction_file = 'data/rfr_2017_04_06_15_45_18.out.csv' # Initial rfr, refactored, max_features=15\n",
    "#prediction_file = 'data/rfr_2017_04_07_00_44_36.out.csv' # Initial rfr, optimized, ntrees=2000, mxdepth=40, mnsleaf=3\n",
    "#prediction_file = 'data/rfr_2017_04_07_23_16_55.out.csv' # Initial rfr, without zoneid information\n",
    "prediction_file = 'data/rfr_2017_04_08_21_31_35.out.csv' # Initial rfr, rm=1\n",
    "solution_file   = 'data/Solution.csv'\n",
    "dt1             = datetime.datetime.strptime(\"2013-08-01 00:00\", \"%Y-%m-%d %H:%M\")\n",
    "dt2             = datetime.datetime.strptime(\"2013-09-30 23:00\", \"%Y-%m-%d %H:%M\")\n",
    "dt3             = datetime.datetime.strptime(\"2013-12-01 00:00\", \"%Y-%m-%d %H:%M\")\n",
    "\n",
    "prediction_dict = {}\n",
    "with open(prediction_file, 'rb') as pfile:\n",
    "    pfreader = csv.reader(pfile)\n",
    "    next(pfreader)\n",
    "    for row in pfreader:\n",
    "        rowid = int(row[0])\n",
    "        try:\n",
    "            targetvar = float(row[1])\n",
    "            prediction_dict[rowid] = targetvar\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "public_solution_dict   = {}\n",
    "private_solution_dict  = {}\n",
    "npass_public           = 0\n",
    "npass_private          = 0\n",
    "with open(solution_file, 'rb') as sfile:\n",
    "    sfreader = csv.reader(sfile)\n",
    "    next(sfreader)\n",
    "    for row in sfreader:\n",
    "        dt = datetime.datetime.strptime(row[2], \"%Y%m%d %H:%M\")\n",
    "        if dt>=dt1 and dt<=dt2:\n",
    "            rowid = int(row[0])\n",
    "            try:\n",
    "                targetvar = float(row[3])\n",
    "                public_solution_dict[rowid] = targetvar\n",
    "            except:\n",
    "                npass_public  += 1\n",
    "        elif dt>dt2 and dt<=dt3:\n",
    "            rowid = int(row[0])\n",
    "            try:\n",
    "                targetvar = float(row[3])\n",
    "                private_solution_dict[rowid] = targetvar\n",
    "            except:\n",
    "                npass_private += 1\n",
    "print('Bad records in public solution: %i, in private solution: %i\\n' %(npass_public,npass_private))\n",
    "nitems = 0\n",
    "sumsqd = 0.0\n",
    "for key,value in public_solution_dict.items():\n",
    "    predval = prediction_dict[key]\n",
    "    sumsqd += (predval-value)**2\n",
    "    nitems += 1\n",
    "rmse = np.sqrt(sumsqd/nitems)\n",
    "print('Public Leader Board:  RMSE = %s, Predictions included: %i' %(rmse,nitems))\n",
    "\n",
    "nitems = 0\n",
    "sumsqd = 0.0\n",
    "for key,value in private_solution_dict.items():\n",
    "    predval = prediction_dict[key]\n",
    "    sumsqd += (predval-value)**2\n",
    "    nitems += 1\n",
    "rmse = np.sqrt(sumsqd/nitems)\n",
    "print('Private Leader Board: RMSE = %s, Predictions included: %i' %(rmse,nitems))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
